{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "103f2188-0808-4ef0-b025-d7cf279ab08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import pyautogui\n",
    "import joblib\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005528b7-4ed6-4a31-a8d4-77e6205bf50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)  # Use webcam\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)\n",
    "mp_draw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d977a5ae-1ea6-4c90-b6fa-df5927d4330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        continue\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(img_rgb)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "    \n",
    "    cv2.imshow(\"Hand Tracking\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8809b0f-549f-476d-b51c-a574f32679c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44f7da09-8663-4c21-b168-49fdaab43642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset directory\n",
    "DATA_DIR = 'gesture_data'\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4fd7a8-7a82-4ad2-9ccb-6879f8669656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your gestures\n",
    "gestures = ['index_up', 'fist', 'palm_open']\n",
    "samples_per_gesture = 100  # Number of samples to collect per gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22e654ff-13d3-46c8-8fbb-99d4548572b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for index_up. Press \"q\" to skip this gesture.\n",
      "Get ready in 3 seconds...\n",
      "Collecting data for fist. Press \"q\" to skip this gesture.\n",
      "Get ready in 3 seconds...\n",
      "Collecting data for palm_open. Press \"q\" to skip this gesture.\n",
      "Get ready in 3 seconds...\n"
     ]
    }
   ],
   "source": [
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "for gesture in gestures:\n",
    "    # Create subdirectory for each gesture\n",
    "    gesture_dir = os.path.join(DATA_DIR, gesture)\n",
    "    if not os.path.exists(gesture_dir):\n",
    "        os.makedirs(gesture_dir)\n",
    "    \n",
    "    print(f'Collecting data for {gesture}. Press \"q\" to skip this gesture.')\n",
    "    print('Get ready in 3 seconds...')\n",
    "    sleep(3)\n",
    "    \n",
    "    sample_count = 0\n",
    "    while sample_count < samples_per_gesture:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "            \n",
    "        # Flip frame horizontally for a mirror effect\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Convert to RGB and process with MediaPipe\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(frame_rgb)\n",
    "        \n",
    "        # Display countdown on screen\n",
    "        cv2.putText(frame, f'Collecting {gesture}: Sample {sample_count+1}/{samples_per_gesture}', \n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            \n",
    "            # Draw hand landmarks\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "            # Extract landmarks and save\n",
    "            landmarks = []\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                landmarks.extend([landmark.x, landmark.y, landmark.z])\n",
    "            \n",
    "            np.save(os.path.join(gesture_dir, f'{sample_count}.npy'), np.array(landmarks))\n",
    "            sample_count += 1\n",
    "            \n",
    "            # Small delay between samples\n",
    "            sleep(0.1)\n",
    "        \n",
    "        cv2.imshow('Data Collection', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20cf7686-f6a8-4769-8682-d90002e39ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b929238-4f3b-4359-b84d-981e2f263966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "gestures = [\"index_up\", \"fist\", \"palm_open\"]\n",
    "X, y = [], []\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for file in os.listdir(f\"gesture_data/{gesture}\"):\n",
    "        data = np.load(f\"gesture_data/{gesture}/{file}\")\n",
    "        X.append(data)\n",
    "        y.append(idx)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d8fde8e-d7bd-4610-b38a-8046d47b1869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gesture_model.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, \"gesture_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31f9623d-9261-4632-a16f-a16737b58148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)  # 0 for default camera\n",
    "\n",
    "# Load the trained gesture recognition model\n",
    "try:\n",
    "    model = joblib.load(\"gesture_model.pkl\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Model file 'gesture_model.pkl' not found.\")\n",
    "    exit(1)\n",
    "\n",
    "# Get screen dimensions\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# Set pyautogui failsafe (move mouse to corner to abort)\n",
    "pyautogui.FAILSAFE = True\n",
    "\n",
    "# For smoothing cursor movement\n",
    "prev_x, prev_y = 0, 0\n",
    "smoothing_factor = 0.5\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        continue\n",
    "    \n",
    "    # Flip image horizontally for mirror effect\n",
    "    img = cv2.flip(img, 1)\n",
    "    \n",
    "    # Convert to RGB for MediaPipe\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process hand landmarks\n",
    "    results = hands.process(img_rgb)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "        \n",
    "        # Draw hand landmarks on image\n",
    "        mp_drawing.draw_landmarks(\n",
    "            img, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        \n",
    "        # Extract landmarks and normalize\n",
    "        data = []\n",
    "        for landmark in hand_landmarks.landmark:\n",
    "            data.extend([landmark.x, landmark.y, landmark.z])\n",
    "        \n",
    "        # Make prediction\n",
    "        try:\n",
    "            prediction = model.predict([data])[0]\n",
    "            \n",
    "            # Perform actions based on prediction\n",
    "            if prediction == 0:  # ðŸ‘† Index Up â†’ Left Click\n",
    "                pyautogui.click()\n",
    "                cv2.putText(img, \"Left Click\", (10, 50), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                \n",
    "            elif prediction == 1:  # âœŠ Fist â†’ Right Click\n",
    "                pyautogui.rightClick()\n",
    "                cv2.putText(img, \"Right Click\", (10, 50), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                \n",
    "            elif prediction == 2:  # âœ‹ Palm Open â†’ Move Cursor\n",
    "                # Get index finger tip coordinates (landmark 8)\n",
    "                x = int(hand_landmarks.landmark[8].x * screen_width)\n",
    "                y = int(hand_landmarks.landmark[8].y * screen_height)\n",
    "                \n",
    "                # Smooth cursor movement\n",
    "                x = int(prev_x * (1 - smoothing_factor) + x * smoothing_factor)\n",
    "                y = int(prev_y * (1 - smoothing_factor) + y * smoothing_factor)\n",
    "                prev_x, prev_y = x, y\n",
    "                \n",
    "                pyautogui.moveTo(x, y)\n",
    "                cv2.putText(img, \"Moving\", (10, 50), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {e}\")\n",
    "    \n",
    "    # Display the image\n",
    "    cv2.imshow(\"Virtual Mouse Gesture Control\", img)\n",
    "    \n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de6d94-200f-48a5-a203-b9734a9637f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec146278-c865-4808-88aa-74d8500fdf87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542984dd-0d8f-4fa2-94ed-18d767d4f8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ad173-64a5-45c5-8db2-111a61fa30b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a2f0d-6fed-4c04-a92b-4c76024a1332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43ca23b-6ea7-41ef-8fa8-f507082cd551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20998119-a6c8-4d45-b252-982a8a4359b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b9f92-103c-4c9d-89b2-7d1a58f80d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa03e69-6bd6-47df-8114-fefb0413ee22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597ac76-d431-43e9-8fc8-7f02fe1981b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11966644-a54e-4424-b69d-e896eaaf578d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a084f0c-4924-4998-a570-24f9a0a9c2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee5732-3a46-4cf7-9fd8-afa8ea6d3c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b707ff6-960c-4efb-aaa2-ceefe7c06b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4d568-a106-452b-b5bd-4baf220886cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb32eb-e578-41bb-943d-95f6233029cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c377b95e-ea74-4d7f-8186-3b4d0ddb1f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0339838-6d3e-4222-8ab9-43b77d837397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc63dd-ac54-4e61-806f-9984e13fa3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50614e7d-c5bc-4aaa-aa63-24b3b751068d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ddf05c-9e7b-4d40-9cd9-5a133e50abf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8fbda-65ca-4c70-b87e-7095af1c0e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f28d8d-74b7-4f62-bc07-694bc7e86497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2ef54-8d42-43e7-bf54-c6ce70ea6239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f750f-edf8-4e08-98ce-acafc30d1872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab12444-0df3-4291-95a1-d7808b64b224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d218316b-c613-4d65-81ac-6b46397d61f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10102ce8-8277-4f2b-912b-abe4ea51de53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659b627-8b13-472d-978c-5d464067a5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930696cc-3f59-4a38-8361-279c84147be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d88b55-c3a0-4c81-acc1-f2dfe64a63f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee6d001-2539-4dfb-bfd2-29d10991efa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ed6cd-7233-429b-860d-a1dd0f71d0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6fa54-a698-4d44-a3da-8aded2c605fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e4efd7-f59c-4b9d-946d-14d4f9d758f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd2f53-edf6-45d0-ba45-300527139b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa1375-9c4e-4cf2-942a-d24fcb65b831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be022caf-08b3-446e-a550-cea7eb3cfe0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b828dd16-66f7-478c-b249-e87998d0d6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f30d6-579c-4826-820a-ac40645a317d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce46ea-6136-4e6d-9769-854138000fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1431f-65cd-44ee-abcc-15938eff035f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809aaa17-aba3-4063-93b0-ca52d308b16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b38984-9e9c-4773-9d7c-428f9e263455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c41c4-6ff6-4fc8-8a05-58d3ba0d6618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb10114-7958-468c-9869-fba198c872d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1821839-52aa-4172-9371-68b811c5ed24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b9273-8b0f-4b2a-a0af-f14cf68a8c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba23d9c-0eab-4621-a284-ed3a83cec637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e046092b-5ed5-4e16-9045-63e50dbd2063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b0bea4-ae46-442c-9577-0e92cba78ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcbf661-d7a6-43a1-abdd-8662d96f70e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11d292-f3fc-4842-bb9f-6f14e88749c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b5583f-65d8-408f-89c6-5a48e57e52f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc510c0-1132-4152-9132-4d6a5c54869c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22029844-77d7-4225-93a4-d80e26b0cd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ac8ef-d5de-4f84-b090-ed3659cae492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c3083-af74-4d98-bacf-5b4488eb83a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2547fe11-22c6-49d0-be1b-1cd044fb4a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a72f4-3483-4cf7-8f37-68392a7c24de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffad2a4-6391-46a6-8932-f3360f83207c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c345eb20-85c6-4604-af9c-7c44f55c0723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c538c-fa2d-4327-8883-e61b2159886d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b24a6-9f49-4a56-90b3-cacd75b47254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba66b05-2b32-4b92-a5d7-e074aeb46466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1413f18-2bf7-4c9a-95c6-e1e4be29148a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7530ad4-0709-43a3-b2e9-68d838f1dc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee7c4d-69e3-4d77-819b-b6e944b48706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2433c4-d0e8-47c9-9e8d-36b6635af61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dc0ca9-fe18-431e-ae2c-8ad1fc245656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2e49d-040f-4ca3-8af4-8808e764da11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ddb53-65d5-48b8-b277-cb4cef188499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fbc19-a1fa-4993-977f-f8d9bf45fc16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b54b3-a649-4755-87ed-d0f4e13b0fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d6fff-ce1b-4b1e-8bd6-32164dcfa96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb9e97-bb31-40f4-8d28-1eaea9650e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ad3d5-6705-4b97-b457-eba21b28b52d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599ca078-2445-4820-b27a-49f29cb0f9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b48164-83c9-4d31-aec4-3a9a39c12357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6868521-5552-4be2-b158-992c5dacc0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680843b6-3790-4201-8138-9ccebc117afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a77b2a-4140-4ba9-be45-3dd81f52c994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7da82-dff5-4a62-bb38-0ba833b2f08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5658a-4f53-419e-bfe2-0cee2fc5a7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1702a38-d91f-44da-bd7b-dc0db19cdf58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5062fc74-3c3b-49a5-85a4-1a1200e1a368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76140282-8b84-4594-aa63-5b848c9ded1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01376d-9209-4ee6-848b-3bb4bfd92540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d812c0-4686-4ec7-82b7-c6ab161c9a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1340787a-da21-4343-89da-9c5e931e0c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
